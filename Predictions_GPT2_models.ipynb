{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Predictions_GPT2_models.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gfhertlein/medical_smart_compose/blob/master/Predictions_GPT2_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eTc3iZahCtv",
        "colab_type": "code",
        "outputId": "4cac9573-1456-414c-fde2-d23d8c48d099",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!git clone https://github.com/huggingface/transformers\n",
        "%cd transformers\n",
        "!pip install .\n",
        "!pip install -r ./examples/requirements.txt"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'transformers'...\n",
            "remote: Enumerating objects: 101, done.\u001b[K\n",
            "remote: Counting objects: 100% (101/101), done.\u001b[K\n",
            "remote: Compressing objects: 100% (86/86), done.\u001b[K\n",
            "remote: Total 26136 (delta 50), reused 24 (delta 7), pack-reused 26035\u001b[K\n",
            "Receiving objects: 100% (26136/26136), 15.85 MiB | 26.22 MiB/s, done.\n",
            "Resolving deltas: 100% (18175/18175), done.\n",
            "/content/transformers\n",
            "Processing /content/transformers\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (1.18.4)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 4.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (4.41.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/2c/8df20f3ac6c22ac224fff307ebc102818206c53fc454ecd37d8ac2060df5/sentencepiece-0.1.86-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.8MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 39.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from transformers==2.9.0) (0.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==2.9.0) (2020.4.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==2.9.0) (0.14.1)\n",
            "Building wheels for collected packages: transformers, sacremoses\n",
            "  Building wheel for transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-2.9.0-cp36-none-any.whl size=631066 sha256=0cd3c0b2bc021980281ccf72f1f452ac5612925c6114023eadfc3d6f900c9933\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-u9eycnh6/wheels/23/19/dd/2561a4e47240cf6b307729d58e56f8077dd0c698f5992216cf\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=468dc87fc622586b8e7c579fbcde26d3ef8cd7fdb7f0da3c5e561a05b31f0450\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built transformers sacremoses\n",
            "Installing collected packages: tokenizers, sentencepiece, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.86 tokenizers-0.7.0 transformers-2.9.0\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 1)) (2.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 2)) (0.22.2.post1)\n",
            "Collecting seqeval\n",
            "  Downloading https://files.pythonhosted.org/packages/34/91/068aca8d60ce56dd9ba4506850e876aba5e66a6f2f29aa223224b50df0de/seqeval-0.0.12.tar.gz\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 4)) (5.4.8)\n",
            "Collecting sacrebleu\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6e/9d/9846507837ca50ae20917f59d83b79246b8313bd19d4f5bf575ecb98132b/sacrebleu-1.4.9-py3-none-any.whl (60kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 4.0MB/s \n",
            "\u001b[?25hCollecting rouge-score\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/6d/2b9a64cba1e4e6ecd4effbf6834b2592b54dc813654f84029758e5daeeb5/rouge_score-0.0.3-py3-none-any.whl\n",
            "Requirement already satisfied: tensorflow_datasets in /usr/local/lib/python3.6/dist-packages (from -r ./examples/requirements.txt (line 7)) (2.1.0)\n",
            "Collecting pytorch-lightning==0.7.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4e/53/0549dd9c44c90e96d217592e094e9c53ef39ae2fed0c5cdb7e57aca65af6/pytorch_lightning-0.7.3-py3-none-any.whl (203kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 15.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.28.1)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.18.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (46.1.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.7.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.6.0.post3)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.34.2)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard->-r ./examples/requirements.txt (line 1)) (0.9.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->-r ./examples/requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: Keras>=2.2.4 in /usr/local/lib/python3.6/dist-packages (from seqeval->-r ./examples/requirements.txt (line 3)) (2.3.1)\n",
            "Collecting portalocker\n",
            "  Downloading https://files.pythonhosted.org/packages/53/84/7b3146ec6378d28abc73ab484f09f47dfa008ad6f03f33d90a369f880e25/portalocker-1.7.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing in /usr/local/lib/python3.6/dist-packages (from sacrebleu->-r ./examples/requirements.txt (line 5)) (3.6.6)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from rouge-score->-r ./examples/requirements.txt (line 6)) (3.2.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.3.1.1)\n",
            "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (2.3)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.12.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (4.41.1)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.1.0)\n",
            "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (19.3.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.16.0)\n",
            "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (0.21.2)\n",
            "Requirement already satisfied: torch>=1.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning==0.7.3->-r ./examples/requirements.txt (line 8)) (1.5.0+cu101)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.2.8)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard->-r ./examples/requirements.txt (line 1)) (2020.4.5.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (3.13)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (1.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (2.10.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from Keras>=2.2.4->seqeval->-r ./examples/requirements.txt (line 3)) (1.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos in /usr/local/lib/python3.6/dist-packages (from tensorflow-metadata->tensorflow_datasets->-r ./examples/requirements.txt (line 7)) (1.51.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard->-r ./examples/requirements.txt (line 1)) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->-r ./examples/requirements.txt (line 1)) (3.1.0)\n",
            "Building wheels for collected packages: seqeval\n",
            "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for seqeval: filename=seqeval-0.0.12-cp36-none-any.whl size=7424 sha256=36ff24f61b4af2b70b1add16e417fb7f900ee4c15ae645bb0f9f5c5c8aeb8bef\n",
            "  Stored in directory: /root/.cache/pip/wheels/4f/32/0a/df3b340a82583566975377d65e724895b3fad101a3fb729f68\n",
            "Successfully built seqeval\n",
            "\u001b[31mERROR: pytorch-lightning 0.7.3 has requirement future>=0.17.1, but you'll have future 0.16.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: seqeval, portalocker, sacrebleu, rouge-score, pytorch-lightning\n",
            "Successfully installed portalocker-1.7.0 pytorch-lightning-0.7.3 rouge-score-0.0.3 sacrebleu-1.4.9 seqeval-0.0.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ToBB9WyBh4AC",
        "colab_type": "code",
        "outputId": "3f0c2bbf-c52b-40d4-ddd1-d7e95de26141",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PK4bHl4W9jSI",
        "colab_type": "text"
      },
      "source": [
        "Results with the \"Raw\" model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "plFmr_HAiWI_",
        "colab_type": "code",
        "outputId": "afe2390f-d283-4f64-ad27-dacb1eb15cc1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!python /content/transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results'\\\n",
        "    --length=10\\\n",
        "    --prompt='The patient felt'\\\n",
        "    --temperature=0.7\\\n",
        "    --k=50\\\n",
        "    --num_return_sequences=3\\\n",
        "    --seed=42\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-04 23:37:38.418656: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/added_tokens.json. We won't load it.\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/vocab.json\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/merges.txt\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/special_tokens_map.json\n",
            "05/04/2020 23:37:39 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/tokenizer_config.json\n",
            "05/04/2020 23:37:40 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/config.json\n",
            "05/04/2020 23:37:40 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "05/04/2020 23:37:40 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results/pytorch_model.bin\n",
            "05/04/2020 23:37:48 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=50, length=10, model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Raw_GPT2_model/Final_Results', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=3, p=0.9, padding_text='', prompt='The patient felt', repetition_penalty=1.0, seed=42, stop_token=None, temperature=0.7, xlm_language='')\n",
            "05/04/2020 23:37:48 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "The patient felt well until she had a\n",
            "respiratory arrest\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "The patient felt\n",
            "uncomfortable at the time of discharge,\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "The patient felt that he had a\n",
            "previous history of hyp\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pnSihf9g9qfb",
        "colab_type": "text"
      },
      "source": [
        "Results with Brief_hospital_course model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kn-GIwn5uKS",
        "colab_type": "code",
        "outputId": "55d41f97-3be6-4f86-be4f-adc5dfb95740",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!python /content/transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results'\\\n",
        "    --length=5\\\n",
        "    --prompt='His neurologic examination was perfect with'\\\n",
        "    --temperature=0.6\\\n",
        "    --k=50\\\n",
        "    --num_return_sequences=5\\\n",
        "    --seed=42\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-04 22:15:47.886469: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/added_tokens.json. We won't load it.\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/vocab.json\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/merges.txt\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/special_tokens_map.json\n",
            "05/04/2020 22:15:49 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/tokenizer_config.json\n",
            "05/04/2020 22:15:50 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/config.json\n",
            "05/04/2020 22:15:50 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"_num_labels\": 2,\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "05/04/2020 22:15:50 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results/pytorch_model.bin\n",
            "05/04/2020 22:16:03 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=50, length=5, model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Brief_hospital_course_GPT2_model/Final_Results', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prompt='His neurologic examination was perfect with', repetition_penalty=1.0, seed=42, stop_token=None, temperature=0.6, xlm_language='')\n",
            "05/04/2020 22:16:03 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "His neurologic examination was perfect with no abnormalities.  He\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "His neurologic examination was perfect with a left-sided sten\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "His neurologic examination was perfect with no changes in the right\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "His neurologic examination was perfect with a normal EKG\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "His neurologic examination was perfect with no signs of active bleeding\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pEIWIyN9-3hh",
        "colab_type": "code",
        "outputId": "c8439336-6b72-4962-e8c9-ef26bc7c67cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 785
        }
      },
      "source": [
        "!python /content/transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model'\\\n",
        "    --length=10\\\n",
        "    --prompt='The patient felt'\\\n",
        "    --temperature=0.3\\\n",
        "    --k=400\\\n",
        "    --num_return_sequences=3\\\n",
        "    --seed=42\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-05 00:09:13.187589: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/added_tokens.json. We won't load it.\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/vocab.json\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/merges.txt\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/special_tokens_map.json\n",
            "05/05/2020 00:09:14 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/tokenizer_config.json\n",
            "05/05/2020 00:09:14 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/config.json\n",
            "05/05/2020 00:09:14 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "05/05/2020 00:09:14 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model/pytorch_model.bin\n",
            "05/05/2020 00:09:22 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=400, length=10, model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_SURGERY_model', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=3, p=0.9, padding_text='', prompt='The patient felt', repetition_penalty=1.0, seed=42, stop_token=None, temperature=0.3, xlm_language='')\n",
            "05/05/2020 00:09:22 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "The patient felt that she was not a candidate for a repeat C\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "The patient felt that he was not ready for discharge to rehab.\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "The patient felt that he was not a candidate for a home treatment\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ_S5T8Up1wC",
        "colab_type": "code",
        "outputId": "3c5783ff-e33e-498f-9aff-cbc297619ab7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        }
      },
      "source": [
        "!python /content/transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model'\\\n",
        "    --length=10\\\n",
        "    --prompt='The patient felt'\\\n",
        "    --temperature=0.7\\\n",
        "    --k=50\\\n",
        "    --num_return_sequences=5\\\n",
        "    --seed=42\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-04 22:42:45.483065: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/added_tokens.json. We won't load it.\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/vocab.json\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/merges.txt\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/special_tokens_map.json\n",
            "05/04/2020 22:42:47 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/tokenizer_config.json\n",
            "05/04/2020 22:42:47 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/config.json\n",
            "05/04/2020 22:42:47 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "05/04/2020 22:42:47 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model/pytorch_model.bin\n",
            "05/04/2020 22:42:55 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=50, length=10, model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_CARDIOTHORACIC_model', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prompt='The patient felt', repetition_penalty=1.0, seed=42, stop_token=None, temperature=0.7, xlm_language='')\n",
            "05/04/2020 22:42:55 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "The patient felt more stable from a cardiac standpoint.  He was\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "The patient felt the pain was from her foot ulcer and that\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "The patient felt he was safe to be discharged home. \n",
            "\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "The patient felt that his pain was most likely related to his chronic\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "The patient felt that she had a high risk of developing a new\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OSDV-P52qEqy",
        "colab_type": "code",
        "outputId": "34c756c1-6fb5-4d7d-b904-8a15157b1467",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!python /content/transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model'\\\n",
        "    --length=10\\\n",
        "    --prompt='The patient felt'\\\n",
        "    --temperature=0.7\\\n",
        "    --num_return_sequences=5\\\n",
        "    --seed=42\\\n",
        "    --k=50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-04 22:42:58.432011: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/added_tokens.json. We won't load it.\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/vocab.json\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/merges.txt\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/special_tokens_map.json\n",
            "05/04/2020 22:43:00 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/tokenizer_config.json\n",
            "05/04/2020 22:43:00 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/config.json\n",
            "05/04/2020 22:43:00 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "05/04/2020 22:43:00 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model/pytorch_model.bin\n",
            "05/04/2020 22:43:08 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=50, length=10, model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_NEURO_model', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prompt='The patient felt', repetition_penalty=1.0, seed=42, stop_token=None, temperature=0.7, xlm_language='')\n",
            "05/04/2020 22:43:08 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "The patient felt that she had been given a good dose of PR\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "The patient felt the pain was not adequately controlled and he was not\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "The patient felt that he had a new onset of his MS and\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "The patient felt to be in a state of shock and was started\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "The patient felt that her mental status was in a stable state and\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ED4dhvQeqtIT",
        "colab_type": "code",
        "outputId": "c15ade25-caf0-4058-aa25-d86dc773088d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 853
        }
      },
      "source": [
        "!python /content/transformers/examples/run_generation.py \\\n",
        "    --model_type=gpt2 \\\n",
        "    --model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model'\\\n",
        "    --length=10\\\n",
        "    --prompt='The patient felt'\\\n",
        "    --temperature=0.7\\\n",
        "    --k=50\\\n",
        "    --num_return_sequences=5\\\n",
        "    --seed=42\\"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-05-04 22:43:11.081582: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   Model name '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, gpt2-xl, distilgpt2). Assuming '/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   Didn't find file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/added_tokens.json. We won't load it.\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/vocab.json\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/merges.txt\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   loading file None\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/special_tokens_map.json\n",
            "05/04/2020 22:43:12 - INFO - transformers.tokenization_utils -   loading file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/tokenizer_config.json\n",
            "05/04/2020 22:43:12 - INFO - transformers.configuration_utils -   loading configuration file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/config.json\n",
            "05/04/2020 22:43:12 - INFO - transformers.configuration_utils -   Model config GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n",
            "05/04/2020 22:43:12 - INFO - transformers.modeling_utils -   loading weights file /content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model/pytorch_model.bin\n",
            "05/04/2020 22:43:21 - INFO - __main__ -   Namespace(device=device(type='cuda'), k=50, length=10, model_name_or_path='/content/drive/My Drive/Data-X Project/Colab Notebooks/Tests_GPT2/Service_Medecine_model', model_type='gpt2', n_gpu=1, no_cuda=False, num_return_sequences=5, p=0.9, padding_text='', prompt='The patient felt', repetition_penalty=1.0, seed=42, stop_token=None, temperature=0.7, xlm_language='')\n",
            "05/04/2020 22:43:21 - WARNING - transformers.modeling_utils -   Setting `pad_token_id` to 50256 (first `eos_token_id`) to generate sequence\n",
            "=== GENERATED SEQUENCE 1 ===\n",
            "The patient felt well after extubation.  He was started\n",
            "=== GENERATED SEQUENCE 2 ===\n",
            "The patient felt to be in a diabetic state and was started on\n",
            "=== GENERATED SEQUENCE 3 ===\n",
            "The patient felt well and was transferred to the floor.  He\n",
            "=== GENERATED SEQUENCE 4 ===\n",
            "The patient felt that his pain was subtherapeutic and he\n",
            "=== GENERATED SEQUENCE 5 ===\n",
            "The patient felt that her symptoms were related to a combination of her\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}